{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from build_dictionary import tokenizer\n",
    "from get_data import GroupData, get_filename, get_data\n",
    "from analysis_query import spelling_correction, AugmentedQuery\n",
    "from get_simularity import Score\n",
    "from dp_similarity import SentenceTransformers\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "* Explain the components and functions of the search engine\n",
    "* Demonstrate demos and test the speed of different cases\n",
    "* Explain the ranking basis with an example\n",
    "* Discuss some possible future extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Data Loader - store each blog as objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class GroupData:\n",
    "    def __init__(self, blog_id, user_id, gender, age, industry, astrology, date, post):\n",
    "        self.blog_id = blog_id\n",
    "        self.user_id = user_id\n",
    "        self.gender = gender\n",
    "        self.age = age\n",
    "        self.industry = industry\n",
    "        self.astrology = astrology\n",
    "        self.date = date\n",
    "        self.post = post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blog ID:\t\t 40 \n",
      "User ID:\t\t 3489929 \n",
      "User's Gender:\t\t female \n",
      "User's Age:\t\t 25 \n",
      "User's Industry:\t Student \n",
      "User's Astrology:\t Cancer \n",
      "Posting Date:\t\t 23,July,2004 \n",
      "Posted blog:\t\t urlLink        Why this is, I do not know. But, OK. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./group_data_objects.pickle', 'rb') as f:\n",
    "    data_lists = pickle.load(f) # Read a pickle file\n",
    "\n",
    "    \n",
    "i = data_lists[40]\n",
    "print(\"Blog ID:\\t\\t\", i.blog_id, \"\\nUser ID:\\t\\t\", i.user_id,\n",
    "      \"\\nUser's Gender:\\t\\t\", i.gender, \"\\nUser's Age:\\t\\t\", i.age,\n",
    "      \"\\nUser's Industry:\\t\", i.industry, \"\\nUser's Astrology:\\t\", i.astrology,\n",
    "      \"\\nPosting Date:\\t\\t\", i.date, \"\\nPosted blog:\\t\\t\", i.post, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. Vocaburary Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 1) A Tokenizer - split paragraphs into a list with all the single tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonkenized blog:  ['why', 'this', 'be', ',', 'i', 'do', 'not', 'know', '.', 'but', ',', 'ok', '.']\n"
     ]
    }
   ],
   "source": [
    "blog = [\"Why this is, I do not know. But, OK.\"]\n",
    "tokenized_blog = tokenizer(blog)[0]  # spaCy\n",
    "print(\"Tonkenized blog: \", tokenized_blog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2) Four Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * Vocaburary Dictionary:  {word &rarr; word frequency in the whole dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * Word-to-ID & ID-to-Word: {word &rarr; word's unique ID; wordword's unique ID &rarr; word}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * Posting Lists: {word's upique ID &rarr; (blog ID, word frequence in this blog, Word frequency in the whole dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 samples of vocaburary dictionary:\n",
      " [('destiny', 1803), ('...', 1001878), ('hear', 36743), ('chosen', 3411), ('life', 167720)] \n",
      "\n",
      "5 samples of word to id:\n",
      " [('destiny', 0), ('...', 1), ('hear', 2), ('chosen', 3), ('life', 4)] \n",
      "\n",
      "5 samples of id to word:\n",
      " [(0, 'destiny'), (1, '...'), (2, 'hear'), (3, 'chosen'), (4, 'life')] \n",
      "\n",
      "5 samples of posting list:\n",
      " 0 [(0, 3, 169), (1, 1, 183), (213, 1, 866), (373, 1, 201), (591, 1, 247)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "voc_dic = pickle.load(open('voc_dic.pickle', 'rb'))\n",
    "print(\"5 samples of vocaburary dictionary:\\n\", list(voc_dic.items())[:5], \"\\n\")\n",
    "voc2id = pickle.load(open('voc2id.pickle', 'rb'))\n",
    "print(\"5 samples of word to id:\\n\", list(voc2id.items())[1:6], \"\\n\")\n",
    "id2voc = pickle.load(open('id2voc.pickle', 'rb'))\n",
    "print(\"5 samples of id to word:\\n\", list(id2voc.items())[:5], \"\\n\")\n",
    "posting_list = pickle.load(open('posting_list.pickle', 'rb'))\n",
    "first_posting_list = next(iter(posting_list.items()))\n",
    "print(\"5 samples of posting list:\\n\", first_posting_list[0], first_posting_list[1][0:5],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. Query Pre-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 1) A Tokenizer\n",
    "  * Recognize name entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'be', 'not', 'happy', 'in', 'new york']\n"
     ]
    }
   ],
   "source": [
    "query = [\"who is not happy in New York\"]\n",
    "tokenized_query = tokenizer(query)[0]  # spaCy\n",
    "print(tokenized_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 2) Spelling Correction (demonstrated in the demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 3) Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Motivation:\n",
    "       * even if some blogs do not contain the excatly keywords in the query,  the system can still consider them to be relevant based on the added augmentation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Presupposition：\n",
    "       * even if a blog does not contain the excatly keywords in the query, if it contains many semantically related words to the keywords, we can assume that the blog is probably relevant in some way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * Steps 1\n",
    "    * if negation marker \"not\" or \"n't\" appears, get the antonyms of the token being modified\n",
    "    * remove the phrase including \"not\" (eg. \"not happy\")\n",
    "    * add antonyms to the query token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "augm_q = AugmentedQuery(tokenized_query)\n",
    "augment_obj = augm_q.augment_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query:\n",
      " ['who', 'be', 'not', 'happy', 'in', 'new york']\n",
      "Antonyms of 'happy':\n",
      " {'unhappy'}\n",
      "Deleted 'not' phrase:\n",
      " ['who', 'be', 'in', 'new york']\n",
      "Revised Query:\n",
      " ['who', 'be', 'in', 'new york', 'unhappy']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Query:\\n\", tokenized_query)\n",
    "print(\"Antonyms of 'happy':\\n\", augment_obj.antonyms_set)\n",
    "for token in augment_obj.delete_set:\n",
    "   tokenized_query.remove(token)\n",
    "print(\"Deleted 'not' phrase:\\n\", tokenized_query)\n",
    "tokenized_query += list(augment_obj.antonyms_set)\n",
    "print(\"Revised Query:\\n\", tokenized_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * Steps 2\n",
    "     * Get each token(except stopwords)'s synonyms, definition of synonyms, hyponyms, hypernyms\n",
    "     * Put them in a set as related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: {'NY', 'New York State', 'New York City', 'Empire State', 'New York', 'Greater New York'} \n",
      "\n",
      "Definition of Synonyms: {'financial', 'river', 'major', 'united', 'form', 'original', 'large', 'new', 'southeastern', 'york', '13', 'colony', 'hudson', 'british', 'city', 'center', 'mid', 'cultural', 'state', 'mouth', 'locate'} \n",
      "\n",
      "Hyponyms: set() \n",
      "\n",
      "Hypernyms: set() \n",
      "\n",
      "Related Words: ['financial', 'river', 'united', 'form', 'original', 'New York City', 'large', 'new', 'Empire State', 'southeastern', 'york', '13', 'colony', 'hudson', 'british', 'city', 'center', 'New York', 'mid', 'NY', 'New York State', 'cultural', 'major', 'state', 'mouth', 'Greater New York', 'locate']\n"
     ]
    }
   ],
   "source": [
    "print(\"Synonyms:\", augment_obj.synonyms_set, '\\n')\n",
    "print(\"Definition of Synonyms:\", augment_obj.definition_set, '\\n')\n",
    "print(\"Hyponyms:\", augment_obj.hyponyms_set, '\\n')\n",
    "print(\"Hypernyms:\", augment_obj.hypernyms_set, '\\n')\n",
    "related_words = list(augment_obj.synonyms_set | augment_obj.definition_set | augment_obj.hyponyms_set | augment_obj.hypernyms_set)\n",
    "print(\"Related Words:\", related_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * another example to show what is hypernyms and hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"float: center;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Hyponym_and_hypernym.svg/1200px-Hyponym_and_hypernym.svg.png\" width=\"70%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:  \n",
      " {'colourise', 'spectral color', 'colorise', 'spectral colour', 'chromatic colour', 'colour', 'color', 'color in', 'chromatic color', 'colorize', 'nobility', 'noblesse', 'discolor', 'colourize', 'discolour', 'colour in'} \n",
      "\n",
      "Hyponyms:  \n",
      " {'violet', 'royal purple', 'reddish purple', 'reddish blue', 'mauve', 'lavender'}\n"
     ]
    }
   ],
   "source": [
    "query = ['purple']\n",
    "augmented_q = AugmentedQuery(query)\n",
    "augment_obj = augmented_q.augment_query()\n",
    "print(\"Hypernyms: \", '\\n', augment_obj.hypernyms_set, '\\n')\n",
    "print(\"Hyponyms: \", '\\n', augment_obj.hyponyms_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Computing Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 1) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised Query: ['who', 'be', 'in', 'new york', 'unhappy']\n",
      "Related words: ['financial', 'river', 'united', 'form', 'original', 'New York City', 'large', 'new', 'Empire State', 'southeastern', 'york', '13', 'colony', 'hudson', 'british', 'city', 'center', 'New York', 'mid', 'NY', 'New York State', 'cultural', 'major', 'state', 'mouth', 'Greater New York', 'locate']\n"
     ]
    }
   ],
   "source": [
    "print(\"Revised Query:\", tokenized_query)\n",
    "print(\"Related Words:\", related_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
