{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from build_dictionary import tokenizer\n",
    "from get_data import GroupData, get_filename, get_data\n",
    "from analysis_query import spelling_correction, AugmentedQuery\n",
    "from get_simularity import Score\n",
    "from dp_similarity import SentenceTransformers\n",
    "from main import main\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 6000)\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Outline\n",
    "* Explain the components and functions of the search engine\n",
    "* Demonstrate demos and test the speed of different cases\n",
    "* Explain the ranking basis with an example\n",
    "* Discuss some possible future extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 1. Data Loader - store each blog as objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class GroupData:\n",
    "    def __init__(self, blog_id, user_id, gender, age, industry, astrology, date, post):\n",
    "        self.blog_id = blog_id\n",
    "        self.user_id = user_id\n",
    "        self.gender = gender\n",
    "        self.age = age\n",
    "        self.industry = industry\n",
    "        self.astrology = astrology\n",
    "        self.date = date\n",
    "        self.post = post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blog ID:\t\t 40 \n",
      "User ID:\t\t 3489929 \n",
      "User's Gender:\t\t female \n",
      "User's Age:\t\t 25 \n",
      "User's Industry:\t Student \n",
      "User's Astrology:\t Cancer \n",
      "Posting Date:\t\t 23,July,2004 \n",
      "Posted blog:\t\t urlLink        Why this is, I do not know. But, OK. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./group_data_objects.pickle', 'rb') as f:\n",
    "    data_lists = pickle.load(f) # Read a pickle file\n",
    "\n",
    "    \n",
    "i = data_lists[40]\n",
    "print(\"Blog ID:\\t\\t\", i.blog_id, \"\\nUser ID:\\t\\t\", i.user_id,\n",
    "      \"\\nUser's Gender:\\t\\t\", i.gender, \"\\nUser's Age:\\t\\t\", i.age,\n",
    "      \"\\nUser's Industry:\\t\", i.industry, \"\\nUser's Astrology:\\t\", i.astrology,\n",
    "      \"\\nPosting Date:\\t\\t\", i.date, \"\\nPosted blog:\\t\\t\", i.post, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. Vocaburary Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 1) A Tokenizer - split paragraphs into a list with all the single tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonkenized blog:\n",
      " ['why', 'this', 'be', ',', 'i', 'do', 'not', 'know', '.', 'but', ',', 'ok', '.']\n"
     ]
    }
   ],
   "source": [
    "blog = [\"Why this is, I do not know. But, OK.\"]\n",
    "tokenized_blog = tokenizer(blog)[0]  # spaCy\n",
    "print(\"Tonkenized blog:\\n\", tokenized_blog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2) Four Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * Vocaburary Dictionary:  {word &rarr; word frequency in the whole dataset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * Word-to-ID & ID-to-Word: {word &rarr; word's unique ID; wordword's unique ID &rarr; word}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "   * Posting Lists: {word's upique ID &rarr; (blog ID, word frequence in this blog, Word frequency in the whole dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 samples of vocaburary dictionary:\n",
      " [('destiny', 1803), ('...', 1001878), ('hear', 36743), ('chosen', 3411), ('life', 167720)] \n",
      "\n",
      "5 samples of word to id:\n",
      " [('destiny', 0), ('...', 1), ('hear', 2), ('chosen', 3), ('life', 4)] \n",
      "\n",
      "5 samples of id to word:\n",
      " [(0, 'destiny'), (1, '...'), (2, 'hear'), (3, 'chosen'), (4, 'life')] \n",
      "\n",
      "5 samples of posting list:\n",
      " 0 [(0, 3, 169), (1, 1, 183), (213, 1, 866), (373, 1, 201), (591, 1, 247)] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "voc_dic = pickle.load(open('voc_dic.pickle', 'rb'))\n",
    "print(\"5 samples of vocaburary dictionary:\\n\", list(voc_dic.items())[:5], \"\\n\")\n",
    "voc2id = pickle.load(open('voc2id.pickle', 'rb'))\n",
    "print(\"5 samples of word to id:\\n\", list(voc2id.items())[1:6], \"\\n\")\n",
    "id2voc = pickle.load(open('id2voc.pickle', 'rb'))\n",
    "print(\"5 samples of id to word:\\n\", list(id2voc.items())[:5], \"\\n\")\n",
    "posting_list = pickle.load(open('posting_list.pickle', 'rb'))\n",
    "first_posting_list = next(iter(posting_list.items()))\n",
    "print(\"5 samples of posting list:\\n\", first_posting_list[0], first_posting_list[1][0:5],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3. Query Pre-processors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 1) A Tokenizer\n",
    "  * Recognize name entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['who', 'be', 'not', 'happy', 'in', 'new york']\n"
     ]
    }
   ],
   "source": [
    "query = [\"who is not happy in New York\"]\n",
    "tokenized_query = tokenizer(query)[0]  # spaCy\n",
    "print(tokenized_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 2) Spelling Correction (demonstrated in the demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 3) Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Motivation\n",
    "       * even if some blogs do not contain the excatly keywords in the query,  the system can still consider them to be relevant based on the added augmentation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Presupposition\n",
    "       * even if a blog does not contain the excatly keywords in the query, if it contains many semantically related words to the keywords, we can assume that the blog is probably relevant in some way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * Steps 1\n",
    "    * if negation marker \"not\" or \"n't\" appears, get the antonyms of the token being modified\n",
    "    * remove the phrase including \"not\" (eg. \"not happy\")\n",
    "    * add antonyms to the query token list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "augm_q = AugmentedQuery(tokenized_query)\n",
    "augment_obj = augm_q.augment_query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Query:\n",
      " ['who', 'be', 'not', 'happy', 'in', 'new york']\n",
      "Antonyms of 'happy':\n",
      " {'unhappy'}\n",
      "Deleted 'not' phrase:\n",
      " ['who', 'be', 'in', 'new york']\n",
      "Revised Query:\n",
      " ['who', 'be', 'in', 'new york', 'unhappy']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Query:\\n\", tokenized_query)\n",
    "print(\"Antonyms of 'happy':\\n\", augment_obj.antonyms_set)\n",
    "for token in augment_obj.delete_set:\n",
    "   tokenized_query.remove(token)\n",
    "print(\"Deleted 'not' phrase:\\n\", tokenized_query)\n",
    "tokenized_query += list(augment_obj.antonyms_set)\n",
    "print(\"Revised Query:\\n\", tokenized_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * Steps 2\n",
    "     * Get each token(except stopwords)'s synonyms, definition of synonyms, hyponyms, hypernyms\n",
    "     * Put them in a set as related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: {'New York State', 'Empire State', 'New York City', 'Greater New York', 'New York', 'NY'} \n",
      "\n",
      "Definition of Synonyms: {'city', 'locate', 'colony', 'new', '13', 'southeastern', 'york', 'original', 'mouth', 'state', 'form', 'major', 'mid', 'large', 'river', 'center', 'cultural', 'hudson', 'financial', 'british', 'united'} \n",
      "\n",
      "Hyponyms: set() \n",
      "\n",
      "Hypernyms: set() \n",
      "\n",
      "Related Words: ['city', 'locate', 'New York City', 'colony', 'new', '13', 'southeastern', 'york', 'Empire State', 'NY', 'original', 'New York State', 'mouth', 'state', 'form', 'Greater New York', 'New York', 'major', 'mid', 'large', 'river', 'cultural', 'hudson', 'financial', 'center', 'british', 'united']\n"
     ]
    }
   ],
   "source": [
    "print(\"Synonyms:\", augment_obj.synonyms_set, '\\n')\n",
    "print(\"Definition of Synonyms:\", augment_obj.definition_set, '\\n')\n",
    "print(\"Hyponyms:\", augment_obj.hyponyms_set, '\\n')\n",
    "print(\"Hypernyms:\", augment_obj.hypernyms_set, '\\n')\n",
    "related_words = list(augment_obj.synonyms_set | augment_obj.definition_set | augment_obj.hyponyms_set | augment_obj.hypernyms_set)\n",
    "print(\"Related Words:\", related_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  * another example to show what is hypernyms and hyponyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img style=\"float: center;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/Hyponym_and_hypernym.svg/1200px-Hyponym_and_hypernym.svg.png\" width=\"70%\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypernyms:  \n",
      " {'nobility', 'color', 'colorise', 'discolor', 'colour in', 'colourise', 'noblesse', 'discolour', 'colorize', 'chromatic colour', 'colourize', 'color in', 'colour', 'spectral color', 'chromatic color', 'spectral colour'} \n",
      "\n",
      "Hyponyms:  \n",
      " {'lavender', 'reddish purple', 'violet', 'mauve', 'royal purple', 'reddish blue'}\n"
     ]
    }
   ],
   "source": [
    "query = ['purple']\n",
    "augmented_q = AugmentedQuery(query)\n",
    "augment_obj = augmented_q.augment_query()\n",
    "print(\"Hypernyms: \", '\\n', augment_obj.hypernyms_set, '\\n')\n",
    "print(\"Hyponyms: \", '\\n', augment_obj.hyponyms_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4. Computing Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### 1) TF-IDF (first rank)\n",
    "  * Score each blog that contains at least one target word \n",
    "    * create a dictionary for each query\n",
    "    * take the blog ID containing the target word as the keyword\n",
    "    * add up the tf-idf scores for each contained target word as the value\n",
    "    * rank the blogs by score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised Query: ['who', 'be', 'in', 'new york', 'unhappy']\n",
      "Related Words: ['city', 'locate', 'New York City', 'colony', 'new', '13', 'southeastern', 'york', 'Empire State', 'NY', 'original', 'New York State', 'mouth', 'state', 'form', 'Greater New York', 'New York', 'major', 'mid', 'large', 'river', 'cultural', 'hudson', 'financial', 'center', 'british', 'united']\n"
     ]
    }
   ],
   "source": [
    "print(\"Revised Query:\", tokenized_query)\n",
    "print(\"Related Words:\", related_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The words in the 'Revised Query' and 'Related Words' are both considered as target word\n",
    "* The TF-IDF score for each 'Related Words' was multiplied by 0.2, as it was considered less important than the query word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2) Embeddings (re-rank)\n",
    "  * Motivation\n",
    "      * the ranking results according to tf-idf scores are influenced by the scope of the blog content covered\n",
    "      * after testing, the high scoring results include exam papers and questionnaires\n",
    "  * Presupposition\n",
    "      * using a pre-trained language model to obtain sentence embeddings and calculating cosine similarity scores for queries and each blog may help to obtain semantically more relevant results\n",
    "  * Pre-trained language model: MiniLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query example:\n",
      "\n",
      " #1 New York \t(Sensitive to named entities)\n",
      " #2 I'm not happy \t(Understand adjective phrases modified by 'not')\n",
      " #3 apple slow \t(Ambiguity)\n",
      " #4 apple pie \t(Ambiguity)\n",
      " #5 Americam \t(Auto correct typo)\n",
      "\n",
      "What do you search for:\n",
      "America\n",
      "\n",
      "Loading...\n",
      "Ranking...\n",
      "Ready to return results...\n",
      "\n",
      "       Score                                               Post               Date  Blog ID  User ID  Gender Age              Industry    Astrology\n",
      "0   0.720023                           What exactly is America?        25,May,2004   561014  3297447    male  24     Museums-Libraries        Libra\n",
      "1   0.691705                                 God Bless America.       04,July,2004   137081   671748    male  27  Communications-Media        Aries\n",
      "2   0.674030                  The world according to America...     09,August,2004   415066   894945    male  27            Technology       Cancer\n",
      "3   0.674030                  The world according to America...       28,June,2004   101595   705633    male  27            Technology       Gemini\n",
      "4   0.644986                       urlLink    God Bless America       28,July,2004   396693  4063865    male  24          Construction        Virgo\n",
      "5   0.605594                  urlLink    america, the beautiful       22,July,2004   570381  2047544  female  23            Technology       Gemini\n",
      "6   0.600781      An excellent Thoreau essay.  This is America.     01,August,2004   460579  3510775    male  25             Education       Cancer\n",
      "7   0.553461  A Strong America. A Great America. An America ...  28,September,2003   606416  1704362    male  17               Student       Pisces\n",
      "8   0.543128  check out  urlLink this place  for all the cra...  01,September,2003   583884  1645698    male  26               Student       Taurus\n",
      "9   0.543128  check out  urlLink this place  for all the cra...  01,September,2003   107922  1685295  female  17               Student    Capricorn\n",
      "10  0.519362  United We Stand, Passively Mute   America stan...    24,January,2004   207311  1563867    male  27                indUnk          Leo\n",
      "11  0.515819                Good by America! See you next week!       29,July,2004    73623  1886224    male  16               Student        Virgo\n",
      "12  0.513621  urlLink    Australia and America really do hav...       12,July,2004   289597  2672549    male  26                indUnk        Virgo\n",
      "13  0.503673          urlLink         Our Heroes America's Best     06,August,2004   344289  3909877    male  26           Engineering       Cancer\n",
      "14  0.479613        urlLink    America, the beautiful.  urlLink       04,July,2004   532971  3757716    male  23            Consulting    Capricorn\n",
      "15  0.469222       In America is good. Go see it.  Made me cry.       01,July,2004   365367  1526231  female  24                indUnk      Scorpio\n",
      "16  0.460205  urlLink    Foreign respect of America goes dow...       11,July,2004   538291  3709486    male  27                indUnk       Cancer\n",
      "17  0.457116  Quote of the Day  \"America is hug deprived, un...     02,August,2004   617737  2297959  female  15               Student       Pisces\n",
      "18  0.451368  urlLink The Village Voice: Features: Paranoid ...        26,May,2004   186069  3462927  female  33                  Arts      Scorpio\n",
      "19  0.442762               urlLink Ronnie James Dio for America       28,June,2004   132790  3705998    male  37                indUnk  Sagittarius\n",
      "Which blog post would you like to see in full content? (number/n)\n",
      "n\n",
      "\n",
      "What do you search for:\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "\n",
    "def get_taxonomy(results,entity,hypernym_list):\n",
    "\n",
    "    '''This recursive function keeps on fetching the hypernyms of the \n",
    "    DBpedia resource recursively till the highest concept or root is reached'''\n",
    "\n",
    "    if entity == 'null':\n",
    "        return hypernym_list\n",
    "    else :\n",
    "        query = ''' \n",
    "        SELECT ?hypernyms \n",
    "        WHERE {<'''+entity+'''> <http://purl.org/linguistics/gold/hypernym> ?hypernyms .}\n",
    "        '''\n",
    "        sparql.setQuery(query)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "        results = sparql.query().convert()\n",
    "        for result in results[\"results\"][\"bindings\"]:\n",
    "            hypernym_list.append(result['hypernyms']['value'])\n",
    "        if len(results[\"results\"][\"bindings\"]) == 0:\n",
    "            return get_taxonomy(results,'null',hypernym_list)\n",
    "        return get_taxonomy(results,results[\"results\"][\"bindings\"][0]['hypernyms']['value'],hypernym_list)\n",
    "\n",
    "def get_taxonomy_of_resource(dbpedia_resource):\n",
    "    list_for_hypernyms=[]\n",
    "    results = {}\n",
    "    results[\"results\"]={}\n",
    "    results[\"results\"][\"bindings\"]=[1,2,3]\n",
    "    taxonomy_list = get_taxonomy(results,dbpedia_resource,list_for_hypernyms)\n",
    "    return taxonomy_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_taxonomy_of_resource(\"http://dbpedia.org/resource/purple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "幻灯片",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
